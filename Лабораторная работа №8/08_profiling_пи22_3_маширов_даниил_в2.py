# -*- coding: utf-8 -*-
"""08_profiling_ПИ22-3_Маширов_Даниил_в2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1laVqkEjvora-0Q5thwNjYA61wsm0UQQV

## Оптимизация выполнения кода, векторизация, Numba

Материалы:
* Макрушин С.В. Лекция 3: Оптимизация выполнения кода, векторизация, Numba
* IPython Cookbook, Second Edition (2018), глава 4
* https://numba.pydata.org/numba-doc/latest/user/5minguide.html

## Задачи для совместного разбора

1. Сгенерируйте массив `A` из `N=1млн` случайных целых чисел на отрезке от 0 до 1000. Пусть `B[i] = A[i] + 100`. Посчитайте среднее значение массива `B`.
"""

import numpy as np

N = 1000000

# Генерация массива A из N случайных целых чисел на отрезке от 0 до 1000
A = np.random.randint(0, 1001, N)

# Вычисление массива B
B = A + 100

# Вычисление среднего значения массива B
mean_B = np.mean(B)

print("Среднее значение массива B:", mean_B)

"""2. Создайте таблицу 2млн строк и с 4 столбцами, заполненными случайными числами. Добавьте столбец `key`, которые содержит элементы из множества английских букв. Выберите из таблицы подмножество строк, для которых в столбце `key` указаны первые 5 английских букв."""

import pandas as pd
import numpy as np
import string

# Создание таблицы с 2 млн строк и 4 столбцами, заполненными случайными числами
df = pd.DataFrame(np.random.randint(0, 100, size=(2000000, 4)), columns=list('ABCD'))

# Добавление столбца key, содержащего случайные английские буквы
df['key'] = np.random.choice(list(string.ascii_lowercase), 2000000)

# Выборка строк, где в столбце key указаны первые 5 английских букв
subset = df[df['key'].str[:5].isin(list(string.ascii_lowercase)[:5])]

subset

"""## Лабораторная работа 3"""

!pip install line_profiler

"""1. В файлах `recipes_sample.csv` и `reviews_sample.csv` (__ЛР 2__) находится информация об рецептах блюд и отзывах на эти рецепты соответственно. Загрузите данные из файлов в виде `pd.DataFrame` с названиями `recipes` и `reviews`. Обратите внимание на корректное считывание столбца(ов) с индексами. Приведите столбцы к нужным типам.

Реализуйте несколько вариантов функции подсчета среднего значения столбца `rating` из таблицы `reviews` для отзывов, оставленных в 2010 году.

A. С использованием метода `DataFrame.iterrows` исходной таблицы;

Б. С использованием метода `DataFrame.iterrows` таблицы, в которой сохранены только отзывы за 2010 год;

В. С использованием метода `Series.mean`.

Проверьте, что результаты работы всех написанных функций корректны и совпадают. Измерьте выполнения всех написанных функций.

"""

# Загрузка данных из файлов
recipes = pd.read_csv('recipes_sample.csv')
reviews = pd.read_csv('reviews_sample.csv')

# Приведение столбцов к нужным типам
recipes['submitted'] = pd.to_datetime(recipes['submitted'])
reviews['date'] = pd.to_datetime(reviews['date'])

def calculate_mean_rating_a(df):
    total_rating = 0
    count = 0
    
    for _, row in df.iterrows():
        if row['date'].year == 2010:
            total_rating += row['rating']
            count += 1
    
    if count == 0:
        return 0
    
    return total_rating / count

mean_rating_a = calculate_mean_rating_a(reviews)
print("Среднее значение рейтинга (метод A):", mean_rating_a)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# calculate_mean_rating_a(reviews)

def calculate_mean_rating_b(df):
    total_rating = 0
    count = 0
    
    for _, row in df[df['date'].dt.year == 2010].iterrows():
        total_rating += row['rating']
        count += 1
    
    if count == 0:
        return 0
    
    return total_rating / count

mean_rating_b = calculate_mean_rating_b(reviews)
print("Среднее значение рейтинга (метод B):", mean_rating_b)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# calculate_mean_rating_b(reviews)

def calculate_mean_rating_c(df):
    mean_rating = df[df['date'].dt.year == 2010]['rating'].mean()
    
    if pd.isnull(mean_rating):
        return 0
    
    return mean_rating

mean_rating_c = calculate_mean_rating_c(reviews)
print("Среднее значение рейтинга (метод C):", mean_rating_c)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# calculate_mean_rating_c(reviews)

"""2. Какая из созданных функций выполняется медленнее? Что наиболее сильно влияет на скорость выполнения? Для ответа использовать профайлер `line_profiler`. Сохраните результаты работы профайлера в отдельную текстовую ячейку и прокомментируйте результаты его работы.

(*). Сможете ли вы ускорить работу функции 1Б, отказавшись от использования метода `iterrows`, но не используя метод `mean`?
"""

import line_profiler

# Создание экземпляра профайлера
profiler = line_profiler.LineProfiler(calculate_mean_rating_a, calculate_mean_rating_b, calculate_mean_rating_c)

# Запуск профайлера
profiler.enable()

# Выполнение функций
mean_rating_a = calculate_mean_rating_a(reviews)
mean_rating_b = calculate_mean_rating_b(reviews)
mean_rating_c = calculate_mean_rating_c(reviews)

# Отключение профайлера и вывод результатов
profiler.disable()
profiler.print_stats()

"""Методы B и C, которые предварительно фильтруют таблицу, могут быть более эффективными по сравнению с методом A, который выполняет операции для всех строк.

3. Вам предлагается воспользоваться функцией, которая собирает статистику о том, сколько отзывов содержат то или иное слово. Измерьте время выполнения этой функции. Сможете ли вы найти узкие места в коде, используя профайлер? Выпишите (словами), что в имеющемся коде реализовано неоптимально. Оптимизируйте функцию и добейтесь значительного (как минимум, на один порядок) прироста в скорости выполнения.
"""

def get_word_reviews_count(df):
    word_reviews = {}
    for _, row in df.dropna(subset=['review']).iterrows():
        recipe_id, review = row['recipe_id'], row['review']
        words = review.split(' ')
        for word in words:
            if word not in word_reviews:
                word_reviews[word] = []
            word_reviews[word].append(recipe_id)
    
    word_reviews_count = {}
    for _, row in df.dropna(subset=['review']).iterrows():
        review = row['review']
        words = review.split(' ')
        for word in words:
            word_reviews_count[word] = len(word_reviews[word])
    return word_reviews_count

import cProfile

def profile_get_word_reviews_count():
    cProfile.run('get_word_reviews_count(reviews)', sort='tottime')

profile_get_word_reviews_count()

from collections import defaultdict

def get_word_reviews_count_optimized(df):
    word_reviews_count = defaultdict(int)
    
    for _, row in df.dropna(subset=['review']).iterrows():
        review = row['review']
        words = review.split(' ')
        
        unique_words = set(words)  # Уникальные слова в отзыве
        
        for word in unique_words:
            word_reviews_count[word] += 1
    
    return word_reviews_count

import line_profiler

# Создание экземпляра профайлера
profiler = line_profiler.LineProfiler(get_word_reviews_count_optimized, get_word_reviews_count)

# Запуск профайлера
profiler.enable()

# Выполнение функций
word_reviews_count_optimized = get_word_reviews_count_optimized(reviews)
word_reviews_count = get_word_reviews_count(reviews)

# Отключение профайлера и вывод результатов
profiler.disable()
profiler.print_stats()

"""4. Напишите несколько версий функции `MAPE` (см. [MAPE](https://en.wikipedia.org/wiki/Mean_absolute_percentage_error)) для расчета среднего абсолютного процентного отклонения значения рейтинга отзыва на рецепт от среднего значения рейтинга по всем отзывам для этого рецепта. 
    1. Без использования векторизованных операций и методов массивов `numpy` и без использования `numba`
    2. Без использования векторизованных операций и методов массивов `numpy`, но с использованием `numba`
    3. С использованием векторизованных операций и методов массивов `numpy`, но без использования `numba`
    4. C использованием векторизованных операций и методов массивов `numpy` и `numba`
    
Измерьте время выполнения каждой из реализаций.

Замечание: удалите из выборки отзывы с нулевым рейтингом.

"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# def calculate_mape_v1(df):
#     total_mape = 0
#     count = 0
#     
#     for _, row in df.iterrows():
#         rating = row['rating']
#         if rating != 0:
#             average_rating = df[df['recipe_id'] == row['recipe_id']]['rating'].mean()
#             mape = abs(rating - average_rating) / average_rating
#             total_mape += mape
#             count += 1
#     
#     if count > 0:
#         return total_mape / count
#     else:
#         return None
#

# Commented out IPython magic to ensure Python compatibility.
# %%time
# from numba import njit
# 
# @njit
# def calculate_mape_v2(df):
#     total_mape = 0
#     count = 0
#     
#     for _, row in df.iterrows():
#         rating = row['rating']
#         if rating != 0:
#             average_rating = df[df['recipe_id'] == row['recipe_id']]['rating'].mean()
#             mape = abs(rating - average_rating) / average_rating
#             total_mape += mape
#             count += 1
#     
#     if count > 0:
#         return total_mape / count
#     else:
#         return None
#

# Commented out IPython magic to ensure Python compatibility.
# %%time
# import numpy as np
# 
# def calculate_mape_v3(df):
#     ratings = df['rating'].values
#     recipe_ids = df['recipe_id'].values
#     
#     mask = (ratings != 0)
#     non_zero_ratings = ratings[mask]
#     non_zero_recipe_ids = recipe_ids[mask]
#     
#     average_ratings = np.zeros_like(non_zero_ratings)
#     unique_recipe_ids = np.unique(non_zero_recipe_ids)
#     
#     for recipe_id in unique_recipe_ids:
#         mask = (non_zero_recipe_ids == recipe_id)
#         average_ratings[mask] = np.mean(non_zero_ratings[mask])
#     
#     mape = np.abs(non_zero_ratings - average_ratings) / average_ratings
#     
#     return np.mean(mape)
#

# Commented out IPython magic to ensure Python compatibility.
# %%time
# from numba import njit
# 
# @njit
# def calculate_mape_v4(df):
#     ratings = df['rating'].values
#     recipe_ids = df['recipe_id'].values
#     
#     mask = (ratings != 0)
#     non_zero_ratings = ratings[mask]
#     non_zero_recipe_ids = recipe_ids[mask]
#     
#     average_ratings = np.zeros_like(non_zero_ratings)
#     unique_recipe_ids = np.unique(non_zero_recipe_ids)
#     
#     for recipe_id in unique_recipe_ids:
#         mask = (non_zero_recipe_ids == recipe_id)
#         average_ratings[mask] = np.mean(non_zero_ratings[mask])
#     
#     mape = np.abs(non_zero_ratings - average_ratings) / average_ratings
#     
#     return np.mean(mape)
#